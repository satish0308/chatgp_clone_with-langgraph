{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf236590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from typing import TypedDict\n",
    "from langchain_core.messages import AnyMessage,HumanMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "from langgraph.checkpoint.mongodb import MongoDBSaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from typing_extensions import Annotated\n",
    "from langgraph.types import CachePolicy\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.runtime import Runtime  \n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a128dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyState(TypedDict):\n",
    "    input: Annotated[list[AnyMessage], add_messages]\n",
    "    output: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "class myruntime(TypedDict):\n",
    "    llm_model: str\n",
    "    api_key: str\n",
    "    end_point: str\n",
    "\n",
    "# checkpointer=InMemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20288ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=os.getenv(\"NVIDIA_API_KEY\")\n",
    "llm_model=os.getenv(\"NVIDIA_MODEL\")\n",
    "end_point=os.getenv(\"NVIDIA_API_ENDPOINT\")\n",
    "mango_db_password=os.getenv(\"MONGO_DB_PASSWORD\")\n",
    "os.environ['NVIDIA_API_KEY']=api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974c4a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c745f1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ce72f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph=StateGraph(MyState,context_schema=myruntime)\n",
    "# def call_llm(state:MyState,runtime:Runtime[myruntime]) -> MyState:\n",
    "#     input_message = state['input']\n",
    "\n",
    "#     llm_model= runtime.context['llm_model']\n",
    "#     # api_key= runtime.context['api_key']\n",
    "#     end_point= runtime.context['end_point']\n",
    "#     # Here you would call your LLM with the input_message\n",
    "#     model = ChatNVIDIA(model=llm_model,base_url=end_point)\n",
    "#     response = model.invoke(input_message)\n",
    "\n",
    "#     return {'output': [response]}\n",
    "\n",
    "# graph.add_node(\"call_llm\",call_llm)\n",
    "# graph.add_edge(START,\"call_llm\")\n",
    "# graph.add_edge(\"call_llm\",END)\n",
    "# build=graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "# context={\"llm_model\": llm_model,\n",
    "#          \"api_key\": api_key,\n",
    "#          \"end_point\": end_point}\n",
    "\n",
    "\n",
    "# config={\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# build.invoke({\"input\":[HumanMessage(\"what is my name\")]},context=context,config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b5bd56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4821b032",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = f\"mongodb+srv://hiremath0308:{mango_db_password}@mycluster.ug67j.mongodb.net/?retryWrites=true&w=majority&appName=mycluster\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db43ee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35371b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with MongoDBSaver.from_conn_string(uri) as checkpointer:\n",
    "#     graph=StateGraph(MyState,context_schema=myruntime)\n",
    "#     def call_llm(state:MyState,runtime:Runtime[myruntime]) -> MyState:\n",
    "#         input_message = state['input']\n",
    "\n",
    "#         llm_model= runtime.context['llm_model']\n",
    "#         # api_key= runtime.context['api_key']\n",
    "#         end_point= runtime.context['end_point']\n",
    "#         # Here you would call your LLM with the input_message\n",
    "#         model = ChatNVIDIA(model=llm_model,base_url=end_point)\n",
    "#         response = model.invoke(input_message)\n",
    "\n",
    "#         return {'output': [response]}\n",
    "\n",
    "#     graph.add_node(\"call_llm\",call_llm)\n",
    "#     graph.add_edge(START,\"call_llm\")\n",
    "#     graph.add_edge(\"call_llm\",END)\n",
    "#     build=graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "#     context={\"llm_model\": llm_model,\n",
    "#             \"api_key\": api_key,\n",
    "#             \"end_point\": end_point}\n",
    "\n",
    "\n",
    "#     config={\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "#     # build.invoke({\"input\":[HumanMessage(\"what is my name\")]},context=context,config=config)\n",
    "#     for chunk in build.stream({\"input\":[HumanMessage(\"what is my name ?\")]},config,context=context,stream_mode=\"updates\",\n",
    "#     ):\n",
    "#         print(chunk[\"call_llm\"][\"output\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd7a37d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build.get_state_history(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b79b3eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Satish. You told me that at the beginning of our conversation.\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"checkpoints_2.db\", check_same_thread=False)\n",
    "    \n",
    "checkpointer = SqliteSaver(conn)\n",
    "graph=StateGraph(MyState,context_schema=myruntime)\n",
    "def call_llm(state:MyState,runtime:Runtime[myruntime]) -> MyState:\n",
    "    input_message = state['input']\n",
    "\n",
    "    llm_model= runtime.context['llm_model']\n",
    "    # api_key= runtime.context['api_key']\n",
    "    end_point= runtime.context['end_point']\n",
    "    # Here you would call your LLM with the input_message\n",
    "    model = ChatNVIDIA(model=llm_model,base_url=end_point)\n",
    "    response = model.invoke(input_message)\n",
    "\n",
    "    return {'output': [response]}\n",
    "\n",
    "graph.add_node(\"call_llm\",call_llm)\n",
    "graph.add_edge(START,\"call_llm\")\n",
    "graph.add_edge(\"call_llm\",END)\n",
    "build=graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "context={\"llm_model\": llm_model,\n",
    "        \"api_key\": api_key,\n",
    "        \"end_point\": end_point}\n",
    "\n",
    "\n",
    "config={\"configurable\": {\"thread_id\": \"satya\"}}\n",
    "\n",
    "# build.invoke({\"input\":[HumanMessage(\"what is my name\")]},context=context,config=config)\n",
    "for chunk in build.stream({\"input\":[HumanMessage(\"what is my name\")]},config,context=context,stream_mode=\"updates\",\n",
    "):\n",
    "    print(chunk[\"call_llm\"][\"output\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca88b860",
   "metadata": {},
   "outputs": [],
   "source": [
    "build=graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69601c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e1b3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
